{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Instantiation\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"FolksDF\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vendredi minuit prochain :GIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+\n",
      "|      Date|              Open|              High|               Low|             Close|  Volume|         Adj Close|\n",
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+\n",
      "|2012-01-03|         59.970001|         61.060001|         59.869999|         60.330002|12668800|52.619234999999996|\n",
      "|2012-01-04|60.209998999999996|         60.349998|         59.470001|59.709998999999996| 9593300|         52.078475|\n",
      "|2012-01-05|         59.349998|         59.619999|         58.369999|         59.419998|12768200|         51.825539|\n",
      "|2012-01-06|         59.419998|         59.450001|         58.869999|              59.0| 8069400|          51.45922|\n",
      "|2012-01-09|         59.029999|         59.549999|         58.919998|             59.18| 6679300|51.616215000000004|\n",
      "|2012-01-10|             59.43|59.709998999999996|             58.98|59.040001000000004| 6907300|         51.494109|\n",
      "|2012-01-11|         59.060001|         59.529999|59.040001000000004|         59.400002| 6365600|         51.808098|\n",
      "|2012-01-12|59.790001000000004|              60.0|         59.400002|              59.5| 7236400|51.895315999999994|\n",
      "|2012-01-13|             59.18|59.610001000000004|59.009997999999996|59.540001000000004| 7729300|51.930203999999996|\n",
      "|2012-01-17|         59.869999|60.110001000000004|             59.52|         59.849998| 8500000|         52.200581|\n",
      "|2012-01-18|59.790001000000004|         60.029999|         59.650002|60.009997999999996| 5911400|         52.340131|\n",
      "|2012-01-19|             59.93|             60.73|             59.75|60.610001000000004| 9234600|         52.863447|\n",
      "|2012-01-20|             60.75|             61.25|         60.669998|61.009997999999996|10378800|53.212320999999996|\n",
      "|2012-01-23|         60.810001|             60.98|60.509997999999996|             60.91| 7134100|         53.125104|\n",
      "|2012-01-24|             60.75|              62.0|             60.75|61.389998999999996| 7362800| 53.54375400000001|\n",
      "|2012-01-25|             61.18|61.610001000000004|61.040001000000004|         61.470001| 5915800| 53.61353100000001|\n",
      "|2012-01-26|         61.799999|             61.84|             60.77|         60.970001| 7436200|         53.177436|\n",
      "|2012-01-27|60.860001000000004|         61.119999|60.540001000000004|60.709998999999996| 6287300|         52.950665|\n",
      "|2012-01-30|         60.470001|             61.32|         60.349998|         61.299999| 7636900|53.465256999999994|\n",
      "|2012-01-31|         61.529999|             61.57|         60.580002|61.360001000000004| 9761500|53.517590000000006|\n",
      "+----------+------------------+------------------+------------------+------------------+--------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importation des fichiers\n",
    "Walmart = spark.read.option(\"header\",'true').option(\"delimiter\",\",\").csv(\"walmart_stock.csv\")\n",
    "Walmart.show()\n",
    "# donc les noms de colonnes sont: Date, Open, Hight, Low, .."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q2 : afficher les colonnes d'un data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Date', 'Open', 'High', 'Low', 'Close', 'Volume', 'Adj Close']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Walmart.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q3 : le schéma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Open: string (nullable = true)\n",
      " |-- High: string (nullable = true)\n",
      " |-- Low: string (nullable = true)\n",
      " |-- Close: string (nullable = true)\n",
      " |-- Volume: string (nullable = true)\n",
      " |-- Adj Close: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Walmart.printSchema()\n",
    "# nullable = true : autorise les valeurs nulles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4 : Create a new dataframe with a column called HV_Ratio that is the ratio of the High Price versus volume of stock traded for a day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+---------+---------+------------------+--------+------------------+--------------------+\n",
      "|      Date|              Open|     High|      Low|             Close|  Volume|         Adj Close|            HV_Ratio|\n",
      "+----------+------------------+---------+---------+------------------+--------+------------------+--------------------+\n",
      "|2012-01-03|         59.970001|61.060001|59.869999|         60.330002|12668800|52.619234999999996|4.819714653321546E-6|\n",
      "|2012-01-04|60.209998999999996|60.349998|59.470001|59.709998999999996| 9593300|         52.078475|6.290848613094555E-6|\n",
      "|2012-01-05|         59.349998|59.619999|58.369999|         59.419998|12768200|         51.825539|4.669412994783916E-6|\n",
      "|2012-01-06|         59.419998|59.450001|58.869999|              59.0| 8069400|          51.45922|7.367338463826307E-6|\n",
      "+----------+------------------+---------+---------+------------------+--------+------------------+--------------------+\n",
      "only showing top 4 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Walmart2 = Walmart.withColumn(\"HV_Ratio\", F.col(\"High\")/F.col(\"Volume\"))\n",
    "Walmart2.head() # juste la premiere ligne\n",
    "Walmart2.show(4) # les 4 premieres lignes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q5 : What day had the Peak High in Price?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|      Date|\n",
      "+----------+\n",
      "|2015-01-13|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "Walmart2.createOrReplaceTempView(\"WalmartSQL\") # transformation du data frame en table !!!!\n",
    "#spark.sql(\"\"\"select Date from WalmartSQL order by High desc\"\"\").first() # solution 1\n",
    "spark.sql(\"\"\"select Date from WalmartSQL order by High desc limit 1\"\"\").show() # solution 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Date='2015-01-13')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DSL donc en spark\n",
    "# Walmart2.orderBy(F.col(\"High\").desc()).select(F.col(\"Date\")).head() # solution 1\n",
    "Walmart2.select(F.col(\"Date\")) \\\n",
    "        .orderBy(F.col(\"High\").desc()) \\\n",
    "        .head() # solution 1 bis ( ressemble au SQL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q6 : What is the mean of the Close column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|          Moyenne|\n",
      "+-----------------+\n",
      "|72.38844998012726|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "spark.sql(\"\"\"select mean(Close) as Moyenne from WalmartSQL\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|          Moyenne|\n",
      "+-----------------+\n",
      "|72.38844998012726|\n",
      "+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DSL\n",
    "#Walmart2.select(\"Close\") \\\n",
    "#        .summary(\"mean\") \\\n",
    "#        .show()  # solution 1\n",
    "Walmart2.agg(F.mean(\"Close\") \\\n",
    "        .alias(\"Moyenne\")) \\\n",
    "        .show() # solution 2 (on peut changer mean par avg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 7 : What is the max and min of the Volume column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|max(Volume)|min(Volume)|\n",
      "+-----------+-----------+\n",
      "|    9994400|   10010500|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "spark.sql(\"\"\"select max(Volume), min(Volume) from WalmartSQL\"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+\n",
      "|max(Volume)|min(Volume)|\n",
      "+-----------+-----------+\n",
      "|    9994400|   10010500|\n",
      "+-----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DSL\n",
    "Walmart2.agg(F.max(\"Volume\"),F.min(\"Volume\")) \\\n",
    "        .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 8 : How many days was the Close lower than 60 dollars?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|count(Date)|\n",
      "+-----------+\n",
      "|         81|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "spark.sql(\"\"\"select count(Date) from WalmartSQL where Close < '60' \"\"\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DSL\n",
    "#Walmart2.filter(F.col(\"Close\") < '60') \\\n",
    "#        .agg(F.count(\"Date\")) \\ # faire l'aggregation apres le filter\n",
    "#        .show()  # solution 1\n",
    "\n",
    "Walmart2.filter(F.col(\"Close\") < '60') \\\n",
    "        .count()   # solution 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 10 : What percentage of the time was the High greater than 80 dollars ?(In other words, (Number of Days High>80)/(Total Days in the dataset))\n",
    "\n",
    "Rq: pas le meme résultat donc à revoir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|Percentage|\n",
      "+----------+\n",
      "|      9.14|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "spark.sql(\"\"\" select round(\n",
    "                (select count(*) from WalmartSQL\n",
    "                where High>='80')\n",
    "                /\n",
    "                (count(*))\n",
    "                * 100\n",
    "                , 2\n",
    "            )\n",
    "as Percentage \n",
    "from WalmartSQL\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|Percentage|\n",
      "+----------+\n",
      "|      9.14|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# DSL\n",
    "Temp = Walmart2.filter(F.col(\"High\")>'80') \\\n",
    "        .agg(F.count(\"*\").alias (\"Comptage\")) \\\n",
    "        .collect()[0][0] \n",
    "Walmart2.agg(F.round((Temp/F.count(\"*\")*100),2).alias(\"Percentage\")) \\\n",
    "        .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 11 : What is the max High per year? per -> group by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|max(High)|Annee|\n",
      "+---------+-----+\n",
      "|75.190002| 2016|\n",
      "|77.599998| 2012|\n",
      "|88.089996| 2014|\n",
      "|81.370003| 2013|\n",
      "|90.970001| 2015|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SQL\n",
    "spark.sql(\"\"\" select max(High), substr(Date,1,4) as Annee from WalmartSQL group by Annee \"\"\").show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (<ipython-input-106-bf40923478f1>, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-106-bf40923478f1>\"\u001b[1;36m, line \u001b[1;32m8\u001b[0m\n\u001b[1;33m    .agg(F.max(\"High\")) \\   # group by AVANT le agg\u001b[0m\n\u001b[1;37m                                                   \n^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "# DSL\n",
    "# Partie 1 : crée une nouelle colonne Annee qui extrait l'annee depuis la variable Date\n",
    "Walmart3 = Walmart2.withColumn(\"Annee\",F.substring(\"Date\",1,4))\n",
    "Walmart3.select(\"Date\", \"Annee\").show(4) \n",
    "\n",
    "# Partie 2 : pour chaque annee, trouvé le max du prix coresspondant\n",
    "Walmart3.groupBy(F.col(\"Annee\")) \\\n",
    "        .agg(F.max(\"High\")) \\   # group by AVANT le agg\n",
    "        .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q12-What is the average Close for each Calendar Month? In other words, across all the years, what is the average Close price for Jan,Feb, Mar, etc... Your result will have a value for each of these months.\n",
    "\n",
    "CHEZ NOUS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DSL"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
